# @package transformer_collective_network.world_model
# World Model configuration for collective learning

# Latent space dimension
latent_dim: 512

# Encoder configuration
encoder_layers: 2  # 2-5 layers as per TD-MPC2
encoder_hidden_dim: 256

# Dynamics model configuration  
dynamics_hidden_dim: 512

# Reward model configuration
reward_hidden_dim: 512
reward_bins: 101  # Discretized reward prediction bins

# World model training parameters
reward_bounds: [-10.0, 10.0]  # Min/max reward for discretization