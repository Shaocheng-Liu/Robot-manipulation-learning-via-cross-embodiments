# @package transformer_collective_network.world_model

# Latent space dimension
latent_dim: 512

# Encoder configuration
num_enc_layers: 2  # Number of encoder layers (2-5 as per TD-MPC2)
enc_dim: 256       # Hidden dimension for encoder layers

# Dynamics and reward model configuration  
mlp_dim: 512       # Hidden dimension for dynamics and reward MLPs

# Reward model configuration
reward_bins: 101  # Discretized reward prediction bins

# Simplicial normalization dimension
simnorm_dim: 8

# World model training parameters
reward_bounds: [-10, 10]  # Min/max reward for discretization

pretrained_dir: "${project_root}/logs/experiment_test/model_dir/model_world"  # 训练 WM 时保存的目录
pretrained_step: null                                      # 指定整数步；null 表示自动找 metadata 或最新
freeze_after_load: true                                     # 蒸馏阶段一般不再训练 WM